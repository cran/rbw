<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Introduction {short-title=&ldquo;Introduction&rdquo; #intro}</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Introduction {short-title=&ldquo;Introduction&rdquo; #intro}</h1>

<p>This paper describes the R package \CRANpkg{rbw}, which implements the method of residual balancing weights for estimating marginal structural models (MSMs) [@zhouResidualBalancingMethod2020a]. MSMs seek to estimate causal effects in the presence of post-treatment confounding — a common issue in the social sciences. In studies of time-varying treatments, prior treatments may affect the confounders of future treatments. For example, research has shown that political candidates&#39; decision to run negative advertisements is shaped by their positions in recent polling data, which are in turn affected by their previous decisions to run negative advertisements [@lauEffectsNegativePolitical2007; @blackwellFrameworkDynamicCausal2013]. Post-treatment confounding can also occur in causal mediation analysis when confounders of the mediator-outcome relationship are affected by the treatment. For example, such a problem arises in 
a study of the mediating role of morality in the effect of shared democracy on public support for war [@tomzPublicOpinionDemocratic2013a]. Post-treatment variables, such as respondents&#39; beliefs about the likelihood of victory, may affect both perceptions of morality and support for military intervention.</p>

<p>MSMs aim to address two types of bias associated with conventional regression methods that adjust naively for post-treatment confounders: overcontrol and collider-stratification bias [@robinsNewApproachCausal1986; -@robinsMarginalStructuralModels2000a]. Conditioning naively on post-treatment confounders can create overcontrol bias as it blocks the effect of the treatment on the outcome that passes through these variables. Additionally, conditioning naively on post-treatment confounders can lead to collider-stratification bias when these variables are affected by unobserved determinants of the outcome. This is because the adjustment will create a spurious association between the treatment and the unobserved variables. </p>

<p>Researchers often use inverse probability weighting (IPW) to fit MSMs [for an in-depth exposition of the method, see @robinsMarginalStructuralModels2000; @robinsMarginalStructuralModels2000a; @coleConstructingInverseProbability2008a]. In longitudinal settings, MSMs with IPW involve fitting a model for the conditional mean of the outcome given the treatment history using weights that break the dependence between past confounders and the treatment at each time point. In essence, the weights create a pseudo-population where the marginal mean of the potential outcomes under a treatment history equals the conditional mean of the observed outcome given the treatment history. The R package \CRANpkg{ipw} provides functions for estimating inverse probability weights [@vanderwalIpwPackageInverse2011; @R-ipw]. </p>

<p>However, IPW&#39;s success depends on correct specification of the models for the conditional distributions of exposure to treatment and/or mediator (hereafter jointly referred to as &ldquo;exposures&rdquo;), which is difficult to achieve in practice. Moreover, even when these models are correctly specified, IPW is inefficient and susceptible to finite-sample bias [@zhouResidualBalancingMethod2020a; @wangDiagnosingBiasInverse2006]. Finally, when the exposures are continuous, IPW may perform poorly due to unreliable estimation of conditional densities [@naimiConstructingInverseProbability2014; @vansteelandtEstimatingDirectEffects2009].</p>

<p>Alternative methods have attempted to mitigate these shortcomings. In particular, Imai and Ratkovic&#39;s [-@imaiCovariateBalancingPropensity2014; -@imaiRobustEstimationInverse2015] covariate balancing propensity score (CBPS) method proposes a set of balancing conditions when estimating the propensity scores. Because it seeks to maximize the covariate balance between the treatment and control groups, this method is less sensitive to model misspecification than IPW. @fongCovariateBalancingPropensity2018 expand CBPS to accommodate continuous exposures, but the challenges involved in modeling conditional densities persist. With this in mind, they have also developed a nonparametric extension that constructs weights that maximize the empirical likelihood while meeting a set of balancing conditions. Though the nonparametric CBPS (npCBPS) circumvents the need for specifying a functional form for the propensity score, it does so at a cost: since the empirical likelihood is not generally convex, the optimization procedure is often slow and may fail to find a solution. The latter can happen, for example, when we have a large number of covariates. The authors advance a workaround that adds flexibility to the covariate balancing conditions and penalizes the remaining imbalance. In doing so, they ensure that a weighting solution exists. Users can implement CBPS in R with the \CRANpkg{CBPS} package [@R-CBPS].</p>

<p>Recently, @zhouResidualBalancingMethod2020a propose the method of residual balancing weights (RBW) for estimating MSMs. RBW involves fitting models for the conditional means of post-treatment confounders given past treatments and confounders and extracting their residual terms. It then uses Hainmueller&#39;s [-@hainmuellerEntropyBalancingCausal2012] entropy balancing method to find weights such that, in the weighted sample, 1) the residuals are orthogonal to future exposures, past treatments, and past confounders, and 2) the relative entropy between the weights and a set of base weights (e.g., survey sampling weights) is minimized. RBW is similar to npCBPS in that it relies on a set of balancing conditions to find the weights and does not require modeling the conditional distributions of the exposures. Both methods can, therefore, be easily adapted to cases where exposures are continuous.<sup>[Other</sup> methods for estimating causal effects of continuous exposures include doubly robust estimators, which model both the treatment and outcome processes and give consistent estimates as long as one of these models is correctly specified. For example, @kennedyNonparametricMethodsDoubly2017 introduce an approach that does not require any parametric assumptions about the effect curve. Instead, it uses flexible data-adaptive methods both to estimate the treatment and outcome models and to subsequently fit the dose-response curve. Readers can install the R package that implements this method from GitHub [@R-npcausal].] Despite their similarities, RBW has a significant computational advantage: the relative entropy metric it uses to construct the weights leads to a convex optimization problem, so finding the weighting solution is computationally expeditious. As shown below, RBW manages to locate the solution considerably faster than npCBPS when we compare the methods&#39; performance for the same problem. </p>

<p>In the sections that follow, we present an overview of the residual balancing method and how, in addition to contexts involving time-varying treatments, we can use it in cases of point treatments and causal mediation analysis. We then discuss the package that implements the method in R (\CRANpkg{rbw}). Next, we describe the functions included in \CRANpkg{rbw} and illustrate their use with various real-world data sets. The final section concludes. </p>

<h1>Overview of residual balancing {short-title=&ldquo;Residual Balancing&rdquo; #residual-balancing}</h1>

<h2>Notation</h2>

<p>Assume we have a study with \(T\ge2\) time points, and we are interested in the effect of a time-varying treatment, \(A_{t}\) (\(1\le t \le T\)), on some end-of-study outcome \(Y\). We also have a vector of observed time-varying confounders, \(L_{t}\), at each time point, which may be affected by prior treatments. \(\bar{A}_{t}=(A_{1},&hellip;,A_{t})\) and \(\bar{L}_{t}=(L_{1},&hellip;,L_{t})\) denote treatment and covariate histories up to time \(t\). Furthermore, \(\bar{A}=\bar{A}_{T}\) and \(\bar{L}=\bar{L}_{T}\) represent a respondent&#39;s complete treatment and covariate histories, respectively. Finally, let \(Y(\bar{a})\) be the potential outcome under some treatment history \(\bar{a}\).</p>

<h2>MSMs</h2>

<p>An MSM is a model for the marginal mean of the potential outcomes under some treatment history:</p>

<p>\begin{equation}
\label{eq:1}
\mathbb{E}[Y(\bar{a})]=\mu(\bar{a};\beta),
\end{equation}</p>

<p>where \(\mu(.)\) is some function and \(\beta\) are a set of parameters capturing the causal effects of interest. We can identify an MSM from observed data under three assumptions:</p>

<ol>
<li>consistency: if \(\bar{A}=\bar{a}\), then \(Y=Y(\bar{a})\);</li>
<li>sequential ignorability: at each time point \(t\), treatment is unconfounded conditional on past treatments and the covariate history up to that point. Formally, \(Y(\bar{a})\indep A_{t}|\bar{A}_{t-1},\bar{L}_{t}\); and</li>
<li>positivity: at each time point \(t\), treatment assignment must not be deterministic. That is, if \(f(\bar{A}_{t-1}=\bar{a}_{t-1}, \bar{L}_{t}=\bar{l}_{t})>0\), then \(f(A_{t}=a_{t}|\bar{A}_{t-1}=\bar{a}_{t-1}, \bar{L}_{t}=\bar{l}_{t})>0\), where \(f(\cdot)\) represents a probability mass or density function.</li>
</ol>

<p>Under these assumptions, @robinsNewApproachCausal1986 shows that the expected value of the potential outcome \(\mathbb{E}[Y(\bar{a})]\) can be identified via the g-computation formula:</p>

<p>\begin{equation}
\label{eq:2}
\mathbb{E}[Y(\bar{a})]=\int&hellip;\int\mathbb{E}[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l}]\prod<sup>{T}<em>{t=1}f(l</em>{t}|\bar{l}<em>{t-1},\bar{a}</em>{t-1})d\mu(l_{t}),</sup>
\end{equation}</p>

<p>where \(\mu()\) is an appropriate dominating measure.  While Equation \ref{eq:2} provides a general formula for identifying causal effects in the presence of time-varying treatments, directly evaluating it is often impractical, particularly when we have many covariates and time periods. </p>

<h2>The rationale behind residual balancing {short-title=&ldquo;RBW Panel&rdquo; #rbw-panel}</h2>

<p>Now consider the formula for the conditional mean of the observed outcome \(Y\) given some treatment history:</p>

<p>\begin{equation}
\label{eq:3}
\mathbb{E}[Y|\bar{A}=\bar{a}]=\int&hellip;\int\mathbb{E}[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l}]\prod<sup>{T}<em>{t=1}f(l</em>{t}|\bar{l}<em>{t-1},\bar{a})d\mu(l</em>{t}).</sup>
\end{equation}</p>

<p>By comparing Equations \ref{eq:2} and \ref{eq:3}, we see that weighting the observed population by </p>

<p>\begin{equation}
\label{eq:4}
W<em>{l}=\prod<sup>{T}</sup></em>{t=1}\frac{f(L<em>{t}|\bar{L}</em>{t-1},\bar{A}<em>{t-1})}{f(L</em>{t}|\bar{L}_{t-1},\bar{A})}
\end{equation}</p>

<p>creates a pseudo-population in which \(f^{*}(l_{t}|\bar{l}_{t-1},\bar{a})=f^{*}(l_{t}|\bar{l}_{t-1},\bar{a}_{t-1})=f(l_{t}|\bar{l}_{t-1},\bar{a}_{t-1})\) and \(\mathbb{E}^{*}[Y|\bar{A}=\bar{a}]=\mathbb{E}^{*}[Y(\bar{a})]=\mathbb{E}[Y(\bar{a})]\), where * represents quantities in the pseudo-population. Estimating the conditional densities of Equation \ref{eq:4} is challenging because \(L_{t}\) is often high-dimensional. </p>

<p>\sloppy @zhouResidualBalancingMethod2020a demonstrate that the condition \(f^{*}(l_{t}|\bar{l}_{t-1},\bar{a})=f^{*}(l_{t}|\bar{l}_{t-1},\bar{a}_{t-1})=f(l_{t}|\bar{l}_{t-1},\bar{a}_{t-1})\) implies a series of moment conditions in the pseudo-population. Most importantly, </p>

<p>\begin{equation}
\label{eq:5}
\mathbb{E}<sup>{<em>}[\delta(g(L<em>{t}))h(\bar{L}</em>{t-1},\bar{A})]=\mathbb{E}<sup>{</sup></em>}[\delta(g(L<em>{t}))]\mathbb{E}<sup>{*}[h(\bar{L}</sup></em>{t-1},\bar{A})]=0,</sup>
\end{equation}</p>

<p>where:</p>

<ul>
<li>\(g(.)\) and \(h(.)\) are scalar functions.</li>
<li>\(\delta(g(L_{t}))\) is the residual of \(g(L_{t})\) with respect to its conditional mean given the observed past: \(\delta(g(L_{t}))=g(L_{t})-\mathbb{E}[g(L_{t})|\bar{L}_{t-1},\bar{A}_{t-1}]\).</li>
</ul>

<p>Residual balancing aims to emulate the moment conditions (\ref{eq:5}) that would hold in the pseudo-population if it were possible to weight the observed population by \(W_{l}\). To do so, the method 1) specifies a set of \(g(\cdot)\) functions, \(G(L_{t})=\{g_{1}(L_{t}),&hellip;,g_{J_{t}}(L_{t})\}\) and a set of \(h(.)\) functions, \(H(\bar{L}_{t-1},\bar{A})=\{h_{1}(\bar{L}_{t-1},\bar{A}),&hellip;,h_{K_{t}}(\bar{L}_{t-1},\bar{A})\}\); 2) computes a set of residual terms \(\delta(g(L_{t}))=g(L_{t})-\mathbb{E}[g(L_{t})|\bar{L}_{t-1},\bar{A}_{t-1}]\); and 3) finds a set of weights such that, for any \(j\), \(k\), and \(t\), the cross-moment of \(\delta(g_{j}(l_{it}))\) and \(h_{k}(\bar{l}_{i,t-1},\bar{a}_{i})\) is zero in the weighted data. That is, RBW locates the \(rbw_{i}\) weights subject to the following balancing conditions:</p>

<p>\begin{equation}
\label{eq:6}
\sum<sup>{n}<em>{i=1}rbw</em>{i}c_{ir}=0,</sup> \,\,\, 1 \le r \le n_{c},
\end{equation}</p>

<p>where \(c_{ir}\) is the rth element of \(\boldsymbol{c}_{i}=\{\delta(g_{j}(l_{it}))h_{k}(\bar{l}_{i,t-1},\bar{a}_{i}); 1 \le j \le J_{t}, 1 \le k \le K_{t}, 1 \le t \le T\}\) and \(n_{c}=\sum^{T}_{t=1}J_{t}K_{t}\) denotes the total number of balancing conditions. The residualized confounders at each time point are balanced across future treatments as well as past treatments and confounders (the observed past). RBW thus adjusts for post-treatment confounding without inducing overcontrol and collider-stratification bias. </p>

<p>Moreover, @zhouResidualBalancingMethod2020a follow @hainmuellerEntropyBalancingCausal2012 and minimize the relative entropy between \(rbw_{i}\) and a set of base weights \(q_{i}\) (e.g., survey sampling weights):</p>

<p>\begin{equation}
\label{eq:7}
\min<em>{rbw</em>{i}}\sum<em>{i}rbw</em>{i}\log (rbw<em>{i}/q</em>{i})
\end{equation}</p>

<p>We can then use the method of Lagrange multipliers to find a weighting solution that minimizes the relative entropy between \(rbw_{i}\) and \(q_{i}\) subject to the \(n_{c}\) balancing constraints. We discuss this procedure in greater depth below when describing the function \code{rbw::eb2()}. The convexity of the relative entropy metric renders it considerably more computationally efficient than nonconvex loss functions that can also be used to construct weights, such as the empirical likelihood [@fongCovariateBalancingPropensity2018]. </p>

<p>A typical implementation of residual balancing can be summarized in three steps:</p>

<ol>
<li>For each covariate \(j\) and at each time point \(t\), fit a linear, logistic, or Poisson regression of \(l_{ijt}\) (depending on its level of measurement) on \(\bar{l}_{i,t-1}\) and \(\bar{a}_{i,t-1}\). Then compute the residuals \(\hat{\delta}(l_{ijt})\). For the covariates in \(L_{1}\) (the first time period), the residuals are computed as deviations from the sample mean: \(\hat{\delta}(l_{ij1})=l_{ij1}-\text{avg}(l_{j1})\). This step relies on the idea that \(g_{j}(L_{t})=L_{jt}\), where \(L_{jt}\) is the jth element of the covariate vector \(L_{t}\), is a natural choice for the set of \(g(.)\) functions constituting \(G(L_{t})\).</li>
<li>Find a set of weights, \(rbw_{i}\), such that:
a) in the weighted sample, the residuals \(\hat{\delta}(l_{ijt})\) are orthogonal to all future treatments and the regressors of \(l_{ijt}\) (i.e., the past treatments and past confounders); 
b) the relative entroy between \(rbw_{i}\) and the base weights \(q_{i}\) is minimized. </li>
<li>Use the weights to fit an MSM. </li>
</ol>

<p>Finally, since \(\mathbb{E}^{*}[Y|\bar{A}=\bar{a}]=\mathbb{E}^{*}[Y(\bar{a})]=\mathbb{E}[Y(\bar{a})]\) in the pseudo-population, we can estimate the marginal effects of interest by fitting a model for the conditional mean of the observed outcome given the treatment history (and possibly a set of baseline confounders) with weights equal to \(rbw_{i}\).  </p>

<h1>Uses of residual balancing {short-title=&ldquo;Uses&rdquo; #uses}</h1>

<p>The rationale described in the previous section is targeted at estimating the causal effects of time-varying treatments. With minor adaptations, we can expand the use of RBW to two other contexts commonly encountered in the social and biomedical sciences: point treatment situations and causal mediation analysis. </p>

<h2>RBW for estimating the average effect of a point treatment {short-title=&ldquo;RBW Treatment&rdquo; #rbw-treatment}</h2>

<p>RBW can be easily adapted to a point treatment situation where the user aims only to adjust for a set of baseline (i.e., time-invariant) confounders to estimate the average treatment effect. To this end, we modify the procedure above as follows: </p>

<ol>
<li>Compute the response residuals \(\hat{\delta}(x_{ij})\) for each baseline confounder \(X_{j}\) by centering it around its sample mean: \(\hat{\delta}(x_{ij})=x_{ij}-\text{avg}({x}_{j})\).</li>
<li>Find a set of weights, \(rbw_{i}\), such that:
a) in the weighted sample, the residuals \(\hat{\delta}(x_{ij})\) are orthogonal to the treatment;
b) the relative entropy between \(rbw_{i}\) and the base weights \(q_{i}\) is minimized.</li>
<li>Use the weights to fit an MSM.</li>
</ol>

<h2>RBW in causal mediation analysis {short-title=&ldquo;RBW Mediation&rdquo; #rbw-mediation}</h2>

<p>In causal mediation analysis, researchers are often concerned with the joint effects of a one-shot treatment, \(A\), and a mediator, \(M\), on some end-of-study outcome \(Y\) when both baseline confounders (\(X\)) and some post-treatment confounders for the mediator-outcome relationship (\(Z\)) are present. With minor adjustments, the RBW implementation for causal mediation analysis is similar to the case with time-varying treatments: </p>

<ol>
<li>As in the point treatment scenario, compute the response residuals \(\hat{\delta}(x_{ij})\) for each baseline confounder \(X_{j}\) by centering it around its sample mean.

<ul>
<li>Note: users may skip this step by including the baseline confounders in the MSM in the final step.</li>
</ul></li>
<li>Estimate the response residuals \(\hat{\delta}(z_{ij})\) for each post-treatment confounder \(Z_{j}\) by fitting a linear, logistic, or Poisson regression of \(z_{ij}\) (depending on its level of measurement) on the treatment \(a_{i}\) and the baseline confounders \(x_{i}\): \(\hat{\delta}(z_{ij})=z_{ij}-\mathbb{E}[z_{ij}|a_{i},x_{i}]\).</li>
<li>Find a set of weights, \(rbw_{i}\), such that:
a) in the weighted sample, i) the baseline residuals \(\hat{\delta}(x_{ij})\) are orthogonal to the treatment \(a_{i}\) and the mediator \(m_{i}\); and ii) the post-treatment residuals \(\hat{\delta}(z_{ij})\) are balanced across the treatment \(a_{i}\), the mediator \(m_{i}\), and the baseline confounders \(x_{i}\);
b) the relative entropy between \(rbw_{i}\) and the base weights \(q_{i}\) is minimized.</li>
<li>Use the weights to fit an MSM for the joint effects of the treatment and the mediator on the outcome:
a) In causal mediation analysis, the potential outcomes of interest are denoted by \(Y(a,m)\) (this is the potential outcome under treatment \(a\) and mediator value \(m\)). We can then express a saturated MSM as \(\mathbb{E}[Y(a,m)]=\alpha_{0}+\alpha_{1}a+\alpha_{2}m+\alpha_{3}am\).
b) Alternatively, the baseline confounders can be included in the MSM if users decide to skip the first step: \(\mathbb{E}[Y(a,m)|X]=\alpha_{0}+\alpha_{1}a+\alpha_{2}m+\alpha_{3}am+\alpha_{4}^{T}X\).
c) Finally, the controlled direct effects (CDE) of the treatment can be estimated as \(\widehat{\text{CDE}}(m)=\mathbb{E}[Y(1,m)-Y(0,m)]=\hat{\alpha}_{1}+\hat{\alpha}_{3}m\). The CDE measures the causal effect of the treatment on the outcome when the mediator is fixed at some value \(m\) for all units.</li>
</ol>

<h1>The R package {short-title=&ldquo;R Package&rdquo; #r-package}</h1>

<p>The R package \CRANpkg{rbw} contains four functions:</p>

<ul>
<li>\code{eb2()}, for generating minimum entropy weights subject to a set of balancing constraints.</li>
<li>\code{rbwPoint()}, for constructing residual balancing weights to estimate the causal effects of one-shot treatments. </li>
<li>\code{rbwMed()}, for constructing residual balancing weights to estimate controlled direct effects in causal mediation analysis.</li>
<li>\code{rbwPanel()}, for constructing residual balancing weights to estimate the marginal effects of time-varying treatments.</li>
</ul>

<p>Next, we explain each of these functions. The package also includes several real-world data sets (\code{advertisement}, \code{peace}, \code{campaign_long}, and \code{campaign_wide}), which we describe and analyze in the examples below. </p>

<h2>Function \code{eb2()} {short-title=&ldquo;eb2&rdquo; #eb2}</h2>

<p>This function is an adaptation of \code{ebal::eb()} [@R-ebal]. It is called internally by other functions in \CRANpkg{rbw} to implement the method of Lagrange multipliers for locating a weighting solution that minimizes the relative entropy between \(rbw_{i}\) and \(q_{i}\) subject to the set of \(n_{c}\) balancing constraints described in Equation \ref{eq:6}. @zhouResidualBalancingMethod2020a impose an additional normalization constraint that ensures that the residual balancing weights sum to the sample size: \(\sum_{i}rbw_{i}=n\). Following @hainmuellerEntropyBalancingCausal2012, the authors obtain the primal optimization problem:</p>

<p>\begin{equation}
\label{eq:8}
\min<em>{rbw</em>{i}}L<sup>{p}=\sum<sup>{n}<em>{i=1}rbw</em>{i}\log</sup></sup> (rbw<em>{i}/q</em>{i})+\sum<sup>{n<em>{c}}</em>{r=1}\lambda<em>{r}\sum<sup>{n}</sup></em>{i=1}rbw<em>{i}c</em>{ir}+\lambda<em>{0}\left(\sum<sup>{n}</sup></em>{i=1}rbw_{i}-n\right),</sup>
\end{equation}</p>

<p>where \(\{\lambda_{1},&hellip;,\lambda_{n_{c}}\}\) are the Lagrange multipliers for the balancing constraints and \(\lambda_{0}\) is the Lagrange multiplier for the normalization constraint. Since the loss function \(L^{p}\) is strictly convex, the first order condition of \(\frac{\partial L^{p}}{\partial rbw_{i}}=0\) implies that the solution for each weight is</p>

<p>\begin{equation}
\label{eq:9}
rbw<em>{i}<sup>{*}=\frac{nq</sup></em>{i}\text{exp}(-\sum<sup>{n<em>{c}}</em>{r=1}\lambda<em>{r}c</em>{ir})}{\sum<sup>{n}<em>{i=1}q</em>{i}\text{exp}(-\sum<sup>{n<em>{c}}</em>{r=1}\lambda<em>{r}c</em>{ir})}.</sup></sup></sup> 
\end{equation}</p>

<p>We can then insert Equation \ref{eq:9} into \(L^{p}\), leading to an unrestricted dual problem:</p>

<p>\begin{equation}
\label{eq:10}
\max<em>{\lambda</em>{r}}L<sup>{d}=-\log</sup> \left(\sum<sup>{n}<em>{i=1}q</em>{i}\text{exp}\left(-\sum<sup>{n<em>{c}}</em>{r=1}\lambda<em>{r}c</em>{ir}\right)\right),</sup></sup>
\end{equation}</p>

<p>or equivalently, </p>

<p>\begin{equation}
\label{eq:11}
\min_{Z}L<sup>{d}=\log</sup> \left(Q&#39;\text{exp}(CZ)\right),
\end{equation}</p>

<p>where \(Q=[q_{1},&hellip;,q_{n}]&lsquo;\), \(C=[\boldsymbol{c}_{1},&hellip;,\boldsymbol{c}_{1}]&rsquo;\), and \(Z=-[\lambda_{1},&hellip;,\lambda_{n_{c}}]&lsquo;\). Since \(L^{d}\) is strictly convex, the solution is guaranteed to be unique — assuming one exists. Given that both the gradient and the Hessian have closed-form expressions, we can solve the problem using Newton&#39;s method. \code{eb2()} implements the algorithm. If convergence is successful, the function tells the user that &ldquo;Entropy minimization converged within tolerance level.&rdquo; Otherwise, it warns that entropy minimization did not converge and suggests increasing the number of iterations or reducing the number of balancing constraints. </p>

<p>The convexity of our optimization problem leads to appreciable computational gains over other methods that use alternative loss functions. This will be demonstrated later when we compare the performance of RBW with that of npCBPS — which uses the empirical likelihood — for the same problem. </p>

<p>\code{eb2()} is used as: </p>

<p>| \code{eb2(C,\,M,\,Q,\,Z = rep(0,\,ncol&copy;),\,max_iter = 200,\,tol = 1e-04,\,print_level = 1)}</p>

<p>and takes the following arguments:</p>

<ul>
<li>\code{C} is a constraint matrix, with each column corresponding to a balancing constraint. </li>
<li>\code{M} is a vector of moment conditions to be met in the reweighted sample (per Equation \ref{eq:6}, this is a vector of zeros with length equal to the number of columns of <code>C</code> when the other functions in <code>rbw</code> call <code>eb2()</code> internally).</li>
<li>\code{Q} is a vector of base weights.</li>
<li>\code{Z} is a vector of Lagrange multipliers to be initialized.</li>
<li>\code{max_iter} determines the maximum number of iterations for Newton&#39;s method.</li>
<li>\code{tol} is a tolerance parameter used to determine convergence. Specifically, convergence is achieved if \code{tol} is greater than the maximum absolute value of the deviations between the moments of the reweighted data and the target moments (i.e., \code{M}).</li>
<li>\code{print_level} determines the level of printing: 

<ul>
<li>\strong{1} normal: print whether the algorithm converges or not.</li>
<li>\strong{2} detailed: print also the maximum absolute value of the deviations between the moments of the reweighted data and the target moments in each iteration.</li>
<li>\strong{3} very detailed: print also the step length of the line searcher in iterations where a full Newton step is excessive</li>
</ul></li>
</ul>

<p>The output returned by \code{eb2()} is a list containing the following elements:</p>

<ul>
<li>\code{W} is a vector of normalized minimum entropy weights.</li>
<li>\code{Z} is a vector of Lagrange multipliers.</li>
<li>\code{converged} is a logical indicator for convergence. </li>
<li>\code{maxdiff} is a scalar indicating the maximum absolute value of the deviation between the moments of the reweighted data and the target moments in each iteration.</li>
</ul>

<h2>Function \code{rbwPoint()} {short-title=&ldquo;rbwPoint&rdquo; #rbwPoint}</h2>

<p>This function produces residual balancing weights to be used in a point treatment situation. It first takes a set of baseline confounders and computes the residuals for each confounder by centering it around its sample mean. Then it calls \code{eb2()} to find a set of weights, \(rbw_{i}\), such that 1) the baseline residuals are orthogonal to the treatment in the weighted sample, and 2) the relative entropy between \({rbw}_{i}\) and the base weights is minimized. Additionally, \code{rbwPoint()} calls a function that ensures that the matrix of balancing constraints comprises only linearly independent columns.</p>

<p>\code{rbwPoint()} is used as:</p>

<p>| \code{rbwPoint(treatment,\,data,\,baseline_x,\,base_weights,\,max_iter = 200,}
|            \code{tol = 1e-04,\,print_level = 1)}</p>

<p>and takes the following arguments:</p>

<ul>
<li>\code{max_iter}, \code{print_level}, and \code{tol} have the same definitions as in \code{eb2()}.</li>
<li>\code{treatment} is a symbol or character string for the treatment variable.</li>
<li>\code{data} is a data frame containing all variables in the model.</li>
<li>\code{baseline_x} is an expression for a set of baseline confounders stored in \code{data} or a character vector of the names of these variables.</li>
<li>\code{base_weights} is an \emph{optional} vector of base weights (or its name). If no value is supplied, the function sets a vectors of ones with length equal to the sample size as the base weights.</li>
</ul>

<p>The output returned by \code{rbwPoint()} is a list containing the following elements:</p>

<ul>
<li>\code{weights} is a vector of residual balancing weights.</li>
<li>\code{constraints} is a matrix of linearly independent residual balancing constraints.</li>
<li>\code{eb_out} contains the results from calling the \code{eb2()} function. </li>
<li>\code{call} is the matched call (the function call with all arguments specified by their full names).</li>
</ul>

<h2>Function \code{rbwMed()} {short-title=&ldquo;rbwMed&rdquo; #rbwMed}</h2>

<p>This function produces residual balancing weights for causal mediation analysis. It takes an \emph{optional} set of baseline confounders (as explained above, users can opt instead to include these covariates in the MSM later) and a list of model objects for the conditional mean of each post-treatment confounder given the treatment and baseline confounders. It then calls \code{eb2()} to find a set of weights, \(rbw_{i}\), such that, in the weighted sample, 1) the baseline residuals are orthogonal to the treatment and the mediator; 2) the post-treatment confounders are balanced across the treatment, the mediator, and the baseline confounders; and 3) the relative entropy between \(rbw_{i}\) and the base weights is minimized.</p>

<p>\code{rbwMed()} takes an additional argument, \code{interact}, a logical variable indicating whether the baseline and post-treatment confounders should be balanced against the treatment-mediator interaction. This argument is set to \code{FALSE} by default, but users suspecting an interaction effect may find it prudent to balance against it. Like \code{rbwPoint()}, \code{rbwMed()} calls a function internally to ensure that only linearly independent columns constitute the matrix of balancing constraints. </p>

<p>It is used as: </p>

<p>| \code{rbwMed(treatment,\,mediator,\,zmodels,\,data,\,baseline_x,\,interact = FALSE,}
|            \code{base_weights,\,max_iter = 200,\,tol = 1e-04,\,print_level = 1)}</p>

<p>and takes the following arguments:</p>

<ul>
<li>\code{treatment}, \code{data}, \code{base_weights}, \code{max_iter}, \code{print_level}, and \code{tol} are defined as in \code{rbwPoint()}.</li>
<li>\code{baseline_x} is an \emph{optional} expression for a set of baseline confounders stored in \code{data} or a character vector of the names of these variables.</li>
<li>\code{mediator} is a symbol or character string representing the mediator variable.</li>
<li>\code{zmodels} is a list of fitted \code{lm} or \code{glm} objects for post-treatment confounders of the mediator-outcome relationship. Users should set this argument to \code{NULL} if there are no post-treatment confounders.</li>
<li>\code{interact} is a logical variable indicating whether baseline and post-treatment confounders should be balanced against the treatment-mediator interaction term(s).</li>
</ul>

<p>The output returned by \code{rbwMed()} is a list containing the same elements as the output from \code{rbwPoint()}. </p>

<h2>Function \code{rbwPanel()} {short-title=&ldquo;rbwPanel&rdquo; #rbwPanel}</h2>

<p>This function produces residual balancing weights for estimating the marginal effects of time-varying treatments. It takes a list of model objects for the conditional mean of each post-treatment confounder given past treatments and past confounders. Then it calls \code{eb2()} to find a set of weights, \(rbw_{i}\), such that 1) residuals of the post-treatment confounders are orthogonal to future treatments and the observed past in the weighted sample, and 2) the relative entropy between \(rbw_{i}\) and the base weights is minimized. Like the other functions, \code{rbwPanel()} ensures that the matrix of balancing constraints consists only of linearly independent columns. </p>

<p>It is used as:</p>

<p>| \code{rbwPanel(treatment,\,xmodels,\,id,\,time,\,data,\,base_weights,\,future = 1L,}
|            \code{max_iter = 200,\,tol = 1e-04,\,print_level = 1)}</p>

<p>and takes the following arguments:</p>

<ul>
<li>\code{data}, \code{base_weights}, \code{max_iter}, \code{print_level}, and \code{tol} are defined as in \code{rbwPoint()} and \code{rbwMed()}.</li>
<li>\code{treatment} is a symbol or character string for the time-varying treatment.</li>
<li>\code{xmodels} is a list of fitted \code{lm} or \code{glm} objects for time-varying confounders.</li>
<li>\code{id} is a symbol or character string for the unit id variable.</li>
<li>\code{time} is a symbol or character string for the time variable. </li>
<li>\code{future} is an integer indicating the number of future treatments in the balancing conditions. When \code{future &gt; 0}, the residualized time-varying covariates are balanced not only with respect to current treatment \(A_{t}\), but also with respect to future treatments \(A_{t+1},&hellip;,A_{t+\texttt{future}}\). The default, \code{future = 1}, assumes away higher-ordered lagged effects of the covariates on the treatment. Users can leave out lagged effects entirely by setting \code{future} to zero.<br/></li>
</ul>

<p>The output returned by \code{rbwPanel()} is essentially the same as those from \code{rbwPoint()} and \code{rbwMed()}. The only difference is that the \code{weights} object, instead of a vector, is now a data frame with two columns: the id variable and the residual balancing weights (the column storing the weights is called \code{rbw}).</p>

<h1>Examples {short-title=&ldquo;Examples&rdquo; #examples}</h1>

<p>We now illustrate the functions \code{rbwPanel()}, \code{rbwPoint()}, and \code{rbwMed()} with data sets \code{advertisement}, \code{peace}, \code{campaign_long}, and \code{campaign_wide}, which are included in \CRANpkg{rbw}. We expect users to rarely need to call \code{eb2()} manually since its primary use is to be called internally by the other functions. Hence, we see little gain in providing a separate example for it. </p>

<h2>Point treatment: effects of political advertisements on campaign contributions {short-title=&ldquo;Point Treatment Example&rdquo; #point-treatment-example}</h2>

<p>@urbanDollarsSidewalkShould2014a studied the effects of televised political advertisements on campaign contributions. Presidential candidates do not tend to deliberately advertise in states where competition for electoral votes is tame. Yet, some areas of noncompetitive states have overlapping media markets with battleground states. Because these media market spillovers do not encompass other forms of campaigning (e.g., rallies, speeches, etc.), the authors can isolate the effect of television advertising by restricting their analyses to noncompetitive states. Their original method involved estimating the propensity score with a logistic model and then conducting propensity score matching. To do so, they dichotomized the political advertising variable to indicate whether zip codes received more than 1000 advertisements. </p>

<p>Deeming this approach inadequate — in part because balancing against a dichotomous treatment does not ensure covariate balance on the underlying continuous variable — @fongCovariateBalancingPropensity2018 revisit the study using the CBPS method applied to a continuous treatment. Next, we examine how RBW fares compared with CBPS and IPW in this point treatment situation.</p>

<p>Importantly, CBPS assumes that the treatment variable is normally distributed. To satisfy this assumption, @fongCovariateBalancingPropensity2018 search across Box-Cox transformations to find the most appropriate transformation of the treatment. Instead, we rely on a simple log transformation in our current example. Q-Q plots show no sizable differences between the two approaches in achieving normality, so we favor the simpler alternative because it avoids extraneous details that divert the example from its primary objective — that is, illustrating RBW&#39;s applicability to a point treatment scenario. Hence, we have \(a_{i}^{*}=\log(a_{i}+1)\), where \(a_{i}\) is the original treatment variable, the total number of political advertisements in a zip code, and \(a_{i}^{*}\) is the transformed treatment. We also have a vector of baseline confounders consisting of the zip code&#39;s log population, population density, log median income, percent Hispanic, percent black, percent over age 65, percent college graduates, and a binary indicator of whether it is possible to commute to the zip code from a competitive state. Finally, \(Y\) represents the outcome, campaign contributions in thousands of dollars. </p>

<p>Our MSM includes the transformed treatment variable and state dummies \(U\) to account for state fixed effects:</p>

<p>\begin{equation}
\label{eq:12}
\mathbb{E}[Y(a<sup>{<em>})|U]=\theta<em>{0}+\theta</em>{1}a<sup>{</sup></em>}</sup> +\theta_{2}<sup>{T}U.</sup>
\end{equation}</p>

<p>The data set \code{advertisement} contains the variables necessary for the analyses. We start by loading the necessary packages and our data set:</p>

<pre><code class="r">library(&quot;rbw&quot;)
data(&quot;advertisement&quot;)
</code></pre>

<p>\code{rbw::rbwPoint()} will construct the residual balancing weights by following the steps described above. It first computes the baseline residuals \(\hat{\delta}(x_{ij})=x_{ij}-\text{avg}({x}_{j})\) and then finds a set of weights such that, in the weighted sample, \(\hat{\delta}(x_{ij})\) are orthogonal to the treatment, and the relative entropy between the residual balancing weights and a set of base weights is minimized. Since \code{advertisement} does not include sampling weights, \code{rbw::rbwPoint()} will set a vector of ones with length equal to the sample size as the base weights. </p>

<pre><code class="r">rbwPoint_fit &lt;-
  rbwPoint(
    treat,
    baseline_x = c(
      log_TotalPop,
      PercentOver65,
      log_Inc,
      PercentHispanic,
      PercentBlack,
      density,
      per_collegegrads,
      CanCommute
    ),
    data =
      advertisement
  )
</code></pre>

<p>Next, we attach the \(rbw_{i}\) weights to the data:</p>

<pre><code class="r">advertisement$rbwPoint_weights &lt;- rbwPoint_fit$weights
</code></pre>

<p>Following most applications of MSMs, we compute standard errors using the robust (&ldquo;sandwich&rdquo;) variance estimator. This can be implemented with the function \code{survey::svydesign()}, which allows us to specify a complex survey design and estimate standard errors consistent with this specification.<sup>[@zhouResidualBalancingMethod2020a</sup> conduct various simulation studies to assess the performance of the robust variance estimator across different methods. They find that the estimator tends to overestimate the true sampling variance for residual balancing across nearly all scenarios, making it consistently conservative for RBW. By contrast, the estimator sometimes overestimates and other times underestimates the true sampling variance for other weighting methods, including CBPS.]</p>

<pre><code class="r">library(&quot;survey&quot;)
rbwPoint_design &lt;- svydesign(ids = ~ 1,
                             weights = ~ rbwPoint_weights,
                             data = advertisement)
</code></pre>

<p>We then use the residual balancing weights to fit the MSM defined in Equation \ref{eq:12}:</p>

<pre><code class="r">rbwPoint_msm &lt;- svyglm(Cont ~ treat + factor(StFIPS),
                       design = rbwPoint_design)
</code></pre>

<p>Since we have transformed our treatment variable, we need to make the necessary adjustments to compute the treatment effect. As @urbanDollarsSidewalkShould2014a suggest, it is informative to study the effect of going from zero to 1,000 political advertisements on campaign contributions. Hence, we create a \code{dose} variable to account for this. If \(a_{i}^{*}=\log(a_{i}+1)\), we can define our dose as \(\log(1000+1)\):</p>

<pre><code class="r">dose &lt;- log(1000 + 1)
</code></pre>

<p>To find the estimate  \(\hat{\tau}_{rbw}\) of the average treatment effect, we multiply the coefficient for the transformed treatment variable by our dose. We also multiply it by 1,000 since the outcome variable is measured in thousands of dollars: </p>

<pre><code class="r">rbwPoint_tau &lt;- 1000 * coef(rbwPoint_msm)[2] * dose
</code></pre>

<p>Next, we use the basic properties of the variance operator to derive the standard error. Again, we multiply the result by 1,000 given the scale of the outcome variable:</p>

<pre><code class="r">rbwPoint_vcov &lt;- stats::vcov(rbwPoint_msm)
rbwPoint_se &lt;- 1000 * dose * sqrt(rbwPoint_vcov[2, 2]) 
</code></pre>

<p>We also report the results using the functions from the \CRANpkg{CBPS} and \CRANpkg{ipw} packages. Recall from the introduction that the parametric CBPS is similar to IPW in that it requires explicit models for the conditional distributions of the treatment. However, it improves IPW by considering a set of balancing conditions during the propensity score estimation, thereby reducing sensitivity to model misspecification. By contrast, the nonparametric CBPS (npCBPS) does not require direct estimation of the propensity score; instead, it finds weights that maximize the empirical likelihood while meeting a set of balancing constraints. As such, like RBW, it avoids the need to specify a propensity score model. Readers can find the code detailing the construction of the CBPS and IPW weights in the supplementary material. </p>

<p>Table \ref{tab:point-treatment-comparison} summarizes the findings. All methods yield relatively similar point estimates and standard errors. In particular, they indicate that going from zero to 1,000 political advertisements increases campaign contributions by around four thousand dollars, on average, although the point estimates from CBPS and IPW are slightly larger than those produced by RBW and npCBPS. The last column shows that different loss functions for the optimization problem can lead to stark differences in computation time. While RBW&#39;s relative entropy metric leads to a convex optimization problem that Newton&#39;s method can solve in less than one second, npCBPS&#39;s algorithm takes much longer to run. </p>

<p>\begin{table}[ht]</p>

<p>\caption{\label{tab:point-treatment-comparison}Comparison of RBW, npCBPS, CBPS, and IPW for a Point Treatment Situation}
\centering
\begin{tabular}[t]{llll}
\toprule
Method &amp; Estimate &amp; Standard Error &amp; \makecell[l]{Computation Time\(in Seconds)}\
\midrule
RBW &amp; 4043 &amp; 2131 &amp; 0.24\
npCBPS &amp; 3916 &amp; 2091 &amp; 38.67\
CBPS &amp; 4181 &amp; 2118 &amp; 4.28\
IPW &amp; 4118 &amp; 2078 &amp; 0.02\
\bottomrule
\multicolumn{4}{l}{\textsuperscript{} Computation time may differ depending on system setup.}\
\multicolumn{4}{l}{\textsuperscript{} System setup used to generate the results:}\
\multicolumn{4}{l}{\textsuperscript{} MacBook Pro (15-inch, 2018), 2.2 GHz 6-Core Intel Core i7, 16GB RAM.}\
\end{tabular}
\end{table}</p>

<p>We next illustrate the use of \code{rbwMed()} and \code{rbwPanel()}. </p>

<h2>Causal mediation analysis: the controlled direct effect of shared democracy on public support for war {short-title=&ldquo;Causal Mediation Example&rdquo; #causal-mediation-example}</h2>

<p>A stylized fact in political science is that democracies do not engage in war with one another. To assess the role of public opinion in keeping the peace, @tomzPublicOpinionDemocratic2013a designed survey experiments that presented participants with a situation where a country was developing nuclear weapons. When describing the situation, the authors randomly and independently changed three characteristics of the country: its political regime (whether it was a democracy), alliance status (whether it had signed a military alliance with the United States), and economic ties (whether it had high levels of trade with the US). The outcome of interest was the respondent&#39;s support for military action on a five-point scale ranging from &ldquo;oppose strongly&rdquo; to &ldquo;favor strongly.&rdquo; The authors found that respondents were considerably less supportive of military action against democracies than otherwise identical autocratic regimes. </p>

<p>They then went on to investigate the causal mechanisms through which shared democracy reduces public enthusiasm for war. In particular, @tomzPublicOpinionDemocratic2013a measured individuals&#39; beliefs about the level of threat posed by the potential adversary, the cost of the intervention, and the likelihood of success. They also collected data on people&#39;s moral concerns about using military force. Their methodological framework focuses on estimating the natural direct and natural indirect effects [@imaiUnpackingBlackBox2011; @imaiIdentificationInferenceSensitivity2010], whose identification assumptions require that no post-treatment confounding of the mediator-outcome relationship exists. As such, the authors examined the role of each mediator separately by assuming they operate independently of one another. Yet, as discussed in @zhouResidualBalancingMethod2020a, beliefs about the threat, cost, and likelihood of success may affect an individual&#39;s perceptions of morality while also influencing support for war directly. By treating these variables as post-treatment confounders, @zhouResidualBalancingMethod2020a analyzed the mediating role of morality using controlled direct effects. </p>

<p>Let \(A\) denote the treatment, whether the country developing nuclear weapons was presented as a democracy, \(M\) the mediator, a dummy variable indicating whether the participant deemed the military action morally wrong, and \(Y\) the outcome, the respondent&#39;s support for war on a five-point scale. We also have a set of baseline confounders (\(X\)) including dummies for the other two randomized treatments (alliance status and economic ties) in addition to several demographic and attitudinal controls.<sup>[For</sup> example, attitudinal controls include respondents&#39; attitudes toward ethnocentrism measured with a series of questions about their opinions on immigration, affirmative action, and gay marriage.] Finally, \(Z\) is a vector of post-treatment confounders comprising measures of beliefs about the threat, cost, and likelihood of success. </p>

<p>Our MSM is thus defined as:</p>

<p>\begin{equation}
\label{eq:13}
\mathbb{E}[Y(a, m)]=\alpha<em>{0}+\alpha</em>{1}a +\alpha<em>{2}m+\alpha</em>{3}am.
\end{equation}</p>

<p>We can alternatively include the baseline confounders in the MSM instead of balancing them across the treatment and the mediator with baseline residuals:</p>

<p>\begin{equation}
\label{eq:14}
\mathbb{E}[Y(a, m)|X]=\alpha<em>{0}+\alpha</em>{1}a +\alpha<em>{2}m+\alpha</em>{3}am + \alpha_{4}<sup>{T}X.</sup>
\end{equation}</p>

<p>The \code{peace} data set includes the variables we will use in the analyses. Let us first consider the approach where the baseline confounders are balanced across the treatment and the mediator using the baseline residuals computed from centering each covariate around its sample mean. </p>

<p>As explained above, RBW in causal mediation analysis requires models for the conditional means of each post-treatment confounder \(Z_{j}\) given the treatment \(a_{i}\) and the baseline confounders \(x_{i}\): \(\hat{\mathbb{E}}[z_{ij}|a_{i},x_{i}]\). Hence, we assume that \code{threatc}, \code{cost}, and \code{successc} are measured on a continuous scale and fit linear models for each: </p>

<pre><code class="r">data(&quot;peace&quot;)
z1 &lt;- lm(threatc ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
           male + white + age + ed4 + democ,
         data = peace)
z2 &lt;- lm(cost ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
           male + white + age + ed4 + democ,
         data = peace)
z3 &lt;- lm(successc ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
           male + white + age + ed4 + democ,
         data = peace)
</code></pre>

<p>We then store the three model objects together in a list to be passed later to the \code{zmodels} argument in \code{rbwMed()}: </p>

<pre><code class="r">zmodels &lt;- list(z1, z2, z3)
</code></pre>

<p>To construct the residual balancing weights, \code{rbwMed()} will 1) compute the baseline residuals \(\hat{\delta}(x_{ij})=x_{ij}-\text{avg}({x}_{j})\) and the post-treatment residuals \(\hat{\delta}(z_{ij})=z_{ij}-\mathbb{E}[z_{ij}|a_{i},x_{i}]\) and 2) find a set of weights such that a) in the weighted sample, the baseline and post-treatment residuals meet the orthogonality requirements described earlier, and b) the relative entropy between the residual balancing weights and a set of base weights is minimized. The function will use a vector of ones as the base weights since \code{peace} does not include sampling weights. We also pass the name of our mediator to the \code{mediator} argument:</p>

<pre><code class="r">rbwMed_fit &lt;- rbwMed(
  treatment = democ,
  mediator = immoral,
  zmodels = zmodels,
  baseline_x = c(ally, trade, h1, i1,
                 p1, e1, r1, male, white, age, ed4),
  data = peace
)
</code></pre>

<p>Next, we attach the weights to \code{peace}:</p>

<pre><code class="r">peace$rbwMed_weights &lt;- rbwMed_fit$weights
</code></pre>

<p>We use \code{survey::svydesign()} to estimate robust standard errors:</p>

<pre><code class="r">rbwMed_design &lt;- svydesign(ids = ~ 1,
                           weights = ~ rbwMed_weights,
                           data = peace)
</code></pre>

<p>Finally, we use the residual balancing weights to fit the MSM from Equation \ref{eq:13}:</p>

<pre><code class="r">rbwMed_msm &lt;- svyglm(strike ~ democ * immoral,
                     design = rbwMed_design)
</code></pre>

<p>Steps are similar for the case where the baseline confounders are not balanced against the treatment and the mediator but instead adjusted in the MSM, as defined in Equation \ref{eq:14}. The models for the conditional means of the post-treatment confounders are the same as before, but we now leave the \code{baseline_x} argument empty:</p>

<pre><code class="r">rbwMed2_fit &lt;- rbwMed(
  treatment = democ,
  mediator = immoral,
  zmodels = zmodels,
  data = peace
)
peace$rbwMed2_weights &lt;- rbwMed2_fit$weights
rbwMed2_design &lt;- svydesign(ids = ~ 1,
                            weights = ~ rbwMed2_weights,
                            data = peace)
rbwMed2_msm &lt;- svyglm(strike ~ ally + trade + h1 + i1 + p1 +
                        e1 + r1 + male + white + age + ed4 + democ * immoral,
                      design = rbwMed2_design)
</code></pre>

<p>We summarize the results in Table \ref{mediation-comparison}. The estimated CDE if respondents lacked any moral qualms about military intervention, i.e., \(\widehat{\text{CDE}}(m=0)=\hat{\mathbb{E}}[Y(1,0)-Y(0,0)]=\hat{\alpha}_{1}\), is \(-0.32\) under the first approach and \(-0.36\) under the second. Both estimates are statistically significant at the level of 0.01. The estimated CDE if respondents had moral qualms about military intervention, i.e., \(\widehat{\text{CDE}}(m=1)=\hat{\mathbb{E}}[Y(1,1)-Y(0,1)]=\hat{\alpha}_{1} + \hat{\alpha}_{3}\), is \(-0.36\) under the first approach and \(-0.22\) under the second.</p>

<p>\begin{table}[ht] \centering 
  \caption{MSM Results for the Controlled Direct Effects of Shared Democracy on Public Support for War} 
  \label{mediation-comparison} 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\[-1.8ex]\toprule 
 &amp; \shortstack{Baseline Confounders \ Balanced} &amp; \shortstack{Baseline Confounders \ Adjusted in the MSM} \
\midrule
 Shared democracy &amp; $-\(0.317\)<sup>{***}$</sup> &amp; $-\(0.360\)<sup>{***}$</sup> \ 
  &amp; (0.098) &amp; (0.080) \ 
  &amp; &amp; \ 
 Moral concerns &amp; $-\(1.272\)<sup>{***}$</sup> &amp; $-\(1.201\)<sup>{***}$</sup> \ 
  &amp; (0.175) &amp; (0.135) \ 
  &amp; &amp; \ 
 Shared democracy * Moral concerns &amp; $-$0.048 &amp; 0.138 \ 
  &amp; (0.210) &amp; (0.157) \ 
\bottomrule \[-1.8ex] 
\multicolumn{3}{l}{$<sup>{*}\(p\)&lt;$0.1;</sup> $<sup>{**}\(p\)&lt;$0.05;</sup> $<sup>{***}\(p\)&lt;$0.01}</sup> \ 
\multicolumn{3}{l}{Robust standard errors in parentheses.} \ 
\end{tabular} 
\end{table} </p>

<h2>Time-varying treatment: the cumulative effect of negative advertising on vote shares {short-title=&ldquo;Time-Varying Example&rdquo; #time-varying-example}</h2>

<p>We conclude this section with an example of RBW applied to a context involving time-varying treatments and confounders. Political scientists have shown interest in examining the cumulative effect of negative campaign advertising on election outcomes [@lauEffectsNegativePolitical2007; @blackwellFrameworkDynamicCausal2013; @imaiRobustEstimationInverse2015]. This is an intricate process because while polling results affect current campaign strategies, they are also constantly shifting, as they respond both to previous results and candidates&#39; use of negative advertising in the past. For their ability to accommodate dynamic causal relationships — particularly since they allow past treatments to affect current outcomes (i.e., &ldquo;carryover effects&rdquo;) and past outcomes to influence current treatment (i.e., &ldquo;feedback effects&rdquo;) [@imaiWhenShouldWe2019] — MSMs are suitable for this research question.</p>

<p>Let \(A_{t}\) represent our continuous treatment, the proportion of campaign advertisements mentioning the adversary in each campaign week, \(L_{t}\) our time-varying confounders, the Democratic share and the share of undecided voters in the polls, and \(Y\) the outcome, the Democratic share of the two-party vote. Additionally, we have a set of baseline confounders \(X\) including total campaign length, election year, and whether the election is senatorial or gubernatorial. </p>

<p>@zhouResidualBalancingMethod2020a define an MSM as follows:</p>

<p>\begin{equation}
\label{eq:15}
\mathbb{E}[Y(\bar{a})|X]=\beta<em>{0}+\beta</em>{1}\text{avg}(\bar{a})+\beta<em>{2}V+\beta</em>{3}\text{avg}(\bar{a})V+\beta_{4}<sup>{T}X,</sup>
\end{equation}</p>

<p>where \(V\) is an indicator of incumbency status used to construct interactions that allow the effect to differ between incumbents and nonincumbents, and \(\text{avg}(\bar{a})\) is the average proportion of advertisements that were negative over the final five weeks of the campaign multiplied by ten (we multiply by ten following @zhouResidualBalancingMethod2020a so that regression coefficients can be interpreted as the effect of a ten-percentage point increase in negative advertising). </p>

<p>\CRANpkg{rbw} contains two data sets associated with this problem: \code{campaign_long} and \code{campaign_wide}. They represent, respectively, the long-format and wide-format data on negative campaign advertising. </p>

<p>Recall that RBW requires us to fit a model for the conditional mean of each covariate at each time point given the observed past. We thus estimate regression models of our time-varying confounders \(L_{t}\) (\(t\ge2\)) on lagged treatment and lagged confounders. We also interact each regressor with the week dummies, thus allowing the coefficients to change over time in a flexible manner:</p>

<pre><code class="r">data(&quot;campaign_long&quot;)
data(&quot;campaign_wide&quot;)
x1 &lt;-
  lm(dem.polls ~ (neg.dem.l1 + dem.polls.l1 + undother.l1) * factor(week),
     data = campaign_long)
x2 &lt;-
  lm(undother ~ (neg.dem.l1 + dem.polls.l1 + undother.l1) * factor(week),
     data = campaign_long)
</code></pre>

<p>We then create a list with the model objects to be passed later to the \code{xmodels} argument in \code{rbwPanel()}: </p>

<pre><code class="r">xmodels &lt;- list(x1, x2)
</code></pre>

<p>To construct the residual balancing weights, \code{rbwPanel()} first extracts the residual terms \(\hat{\delta}(L_{t})\) from the models above. Note that for each covariate in \(L_{1}\) (the first time period), the residuals are computed as deviations from the sample mean. Then the function finds a set of weights, such that, in the weighted sample, the residuals are orthogonal to current and future treatments as well as the regressors of \(L_{jt}\), and the relative entropy between the residual balancing weights and the base weights is minimized. Note that we set the \code{future} argument to zero to replicate the results from @zhouResidualBalancingMethod2020a since the authors balance the residualized time-varying confounders only with respect to the current treatment, thus assuming away lagged effects of the covariates on the treatment.<sup>[The</sup> negative advertising data set spans five weeks, so users interested in considering lagged effects of the time-varying covariates on the treatment may set \code{future &gt; 0}, up to \code{future = 4}.] Since our data do not include sampling weights, a vector of ones is used as the base weights. Additionally, we need to pass arguments indicating the unit id and the time variables due to the longitudinal structure of our data set. </p>

<pre><code class="r">rbwPanel_fit &lt;- rbwPanel(
  treatment = neg.dem,
  xmodels = xmodels,
  id = id,
  time = week,
  data = campaign_long,
  future = 0
)
</code></pre>

<p>We now attach the weights to \code{campaign_wide} using the pipe operator and the \code{left_join()} function from the package \CRANpkg{dplyr} (this merging is permitted because the \code{weights} object returned by \code{rbwPanel()} is a data frame containing the id variable and the residual balancing weights):</p>

<pre><code class="r">library(&quot;dplyr&quot;)
campaign_wide &lt;- campaign_wide %&gt;%
  left_join(rbwPanel_fit$weights, by = &quot;id&quot;)
</code></pre>

<p>We use the functions from \CRANpkg{dplyr} to rename the weights so that our variable&#39;s name is consistent with the previous examples: </p>

<pre><code class="r">campaign_wide &lt;- campaign_wide %&gt;%
  rename(rbwPanel_weights = rbw)
</code></pre>

<p>Again, we use \code{survey::svydesign()} to compute robust standard errors:</p>

<pre><code class="r">rbwPanel_design &lt;- svydesign(ids = ~ 1,
                             weights = ~ rbwPanel_weights,
                             data = campaign_wide)
</code></pre>

<p>Finally, we use the residual balancing weights to fit the MSM from Equation \ref{eq:15}:</p>

<pre><code class="r">rbwPanel_msm &lt;- svyglm(demprcnt ~ ave_neg * deminc + camp.length +
                         factor(year) + office,
                       design = rbwPanel_design)
</code></pre>

<p>We report the model results in Table \ref{time-varying-model}. The estimate for nonincumbents is \(0.49\) and for incumbents is \(0.49-1.48=-0.99\). The effect of negative advertisement for nonincumbents is positive though not statistically significant — a ten percentage point increase in the proportion of negative advertising throughout the last five weeks of the campaign increases the Democratic vote share by about half a percentage point, on average. However, the interaction term is significant at the level of 0.01, and incumbents see a sizeable negative effect from negative advertising: a ten percentage point increase in negative advertising reduces a candidate&#39;s vote share by about one percentage point, on average. </p>

<p>\begin{table}[ht] \centering 
  \caption{MSM Results for the Cumulative Effect of Negative Advertising on Vote Shares} 
  \label{time-varying-model} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\[-1.8ex]\toprule
 Average proportion &amp; 0.490 \ 
  &amp; (0.315) \ 
  &amp; \ 
 Incumbency &amp; 14.971\(^{***}\) \ 
  &amp; (2.823) \ 
  &amp; \ 
 Average proportion * Incumbency &amp; $-\(1.484\)<sup>{***}$</sup> \ 
  &amp; (0.531) \ 
\bottomrule \[-1.8ex] 
\multicolumn{2}{l}{$<sup>{*}\(p\)&lt;$0.1;</sup> $<sup>{**}\(p\)&lt;$0.05;</sup> $<sup>{***}\(p\)&lt;$0.01}</sup> \ 
\multicolumn{2}{l}{Robust standard errors in parentheses.} \ 
\end{tabular} 
\end{table} </p>

<p>We conclude by comparing RBW&#39;s computational performance to CBPS for a dichotomized version of the treatment representing whether more than 10% of the candidate&#39;s advertising was negative for each week. We use this dichotomized variable because CBPS has not been extended to work with continuous treatments in longitudinal settings. Additionally, we do not compare RBW to npCBPS because the latter&#39;s use is restricted to point treatment situations. Lastly, though we can construct IPW weights almost immediately, @zhouResidualBalancingMethod2020a show that IPW yields considerably larger effect estimates than RBW and CBPS for this particular case (likely due to the method&#39;s susceptibility to model misspecification), so we do not report the IPW results. </p>

<p>Let us first construct the RBW weights. The steps are identical to the ones detailed above for the continuous treatment, the only change being the name of our treatment variable. Next, we use the \code{CBMSM()} function from the \code{CBPS} package to generate our CBPS weights. To facilitate comparisons of computation time, we also call \code{Sys.time()} before and after running the functions that produce the weights in each package. The scalar objects \code{rbwPanel_time} and \code{CBPSPanel_time} store how long each method takes to construct the corresponding weights. </p>

<pre><code class="r">m1 &lt;-
  lm(dem.polls ~ (d.gone.neg.l1 + dem.polls.l1 + undother.l1) * factor(week),
     data = campaign_long)
m2 &lt;-
  lm(undother ~ (d.gone.neg.l1 + dem.polls.l1 + undother.l1) * factor(week),
     data = campaign_long)

xmodels &lt;- list(m1, m2)

rbwPanel_start &lt;- Sys.time()
rbwPanel_fit &lt;- rbwPanel(
  treatment = neg.dem,
  xmodels = xmodels,
  id = id,
  time = week,
  data = campaign_long,
  future = 0
)
rbwPanel_end &lt;- Sys.time()
rbwPanel_time &lt;- rbwPanel_end - rbwPanel_start
</code></pre>

<pre><code class="r">CBPSPanel_form &lt;-
  &quot;d.gone.neg ~ d.gone.neg.l1 + dem.polls + undother + camp.length + deminc + office + factor(year)&quot;

CBPSPanel_start &lt;- Sys.time()
CBPSPanel_fit &lt;-
  CBMSM(
    formula = CBPSPanel_form,
    time = campaign_long$week,
    id = campaign_long$demName,
    data = campaign_long,
    type = &quot;MSM&quot;,
    iterations = NULL,
    twostep = TRUE,
    msm.variance = &quot;approx&quot;,
    time.vary = TRUE
  )
CBPSPanel_end &lt;- Sys.time()
CBPSPanel_time &lt;- CBPSPanel_end - CBPSPanel_start
</code></pre>

<p>The output below shows the computation times:</p>

<pre><code class="r">rbwPanel_time
</code></pre>

<pre><code>## Time difference of 0.03252983 secs
</code></pre>

<pre><code class="r">CBPSPanel_time
</code></pre>

<pre><code>## Time difference of 27.95713 secs
</code></pre>

<p>Whereas RBW takes less than one second to construct the weights, CBPS takes much longer. Hence, the longitudinal setting presents the same pattern we saw above for the point treatment situation: RBW has considerable gains in computational performance over alternative methods of constructing weights for MSMs. Since our focus has been on comparing computational performances, we omit the effect estimates for the dichotomized treatment. As shown in @zhouResidualBalancingMethod2020a, the results are broadly consistent with those based on the continuous treatment, with RBW and CBPS yielding similar point estimates.  </p>

<h1>Conclusion {short-title=&ldquo;Conclusion&rdquo; #conclusion}</h1>

<p>Compared to other methods of constructing weights for MSMs, RBW has several advantages. In particular, it does not require modeling the conditional distributions of exposures and is thus easy to use with continuous treatments. Previous simulation studies suggest that it is often more efficient and more robust to model misspecification than alternative weighting strategies [@zhouResidualBalancingMethod2020a]. RBW is also favorable from a computational perspective. Its procedure for finding weights involves a convex optimization problem, allowing RBW to locate a solution substantially faster than alternative methods whose optimization relies on nonconvex loss functions — such as the recently proposed nonparametric version of CBPS, which uses the empirical likelihood [@fongCovariateBalancingPropensity2018]. Table \ref{tab:method-comparison} sums up these comparisons. </p>

<p>\begin{table}[ht]</p>

<p>\caption{\label{tab:method-comparison}Comparison of Methods and Software Implementation}
\centering
\begin{tabular}[t]{ccccc}
\toprule
Method &amp; \makecell[c]{Models for\Conditional Distributions of\Exposures} &amp; \makecell[c]{Balancing\Constraints} &amp; \makecell[c]{Implemented for\Time-varying\Treatments?} &amp; R Package\
\midrule
IPW &amp; Required &amp; Absent &amp; Yes &amp; \pkg{ipw}\
CBPS &amp; Required &amp; Present &amp; Yes &amp; \pkg{CBPS}\
npCBPS &amp; Not Required &amp; Present &amp; No &amp; \pkg{CBPS}\
RBW &amp; Not Required &amp; Present &amp; Yes &amp; \pkg{rbw}\
\bottomrule
\end{tabular}
\end{table}</p>

<p>After explaining the underlying logic of RBW, we have described its implementation in the R package \CRANpkg{rbw}. With examples from several data sets, we have demonstrated the use of \CRANpkg{rbw} in three distinct contexts: effect estimation for point treatments, causal mediation analysis, and effect estimation for time-varying treatments with time-varying confounders.</p>

<p>Nonetheless, RBW is not without limitations. In particular, it depends on models for the conditional means of post-treatment confounders. When these models are incorrectly specified, the pseudo-population generated by residual balancing weights will fail to mimic the original unweighted population, and our estimates will be biased. Even when these models are correctly specified, RBW may also yield biased estimates when we have insufficient balancing conditions. Adding more functions such as cross-products and high-order terms to the set \(G(L_{t})=\{g_{1}(L_{t}),&hellip;,g_{J_{t}}(L_{t})\}\), thereby increasing the number of balancing constraints, may help — though at the risk of making exact balance infeasible. A possible extension to RBW would be to allow for approximate balance with a penalty for the remaining imbalance in the optimization problem [@fongCovariateBalancingPropensity2018]. Finally, we have relied on the &ldquo;sandwich&rdquo; variance estimator to compute standard errors. Though @zhouResidualBalancingMethod2020a demonstrate by simulation studies that this estimator is likely conservative for RBW, the method does not provide a variance estimator tailored to addressing the estimation uncertainty of the RBW weights. </p>

<p>Despite these limitations, RBW will be useful to many social scientists interested in using marginal structural models to study causality in dynamic settings. We will continue to upgrade the package by expanding RBW&#39;s ranges of applicability &mdash; specifically, to censored data, to contexts involving repeated outcome measures such as survival data [@hernanEstimatingCausalEffect2002; @hernanMarginalStructuralModels2000], and to cases where, as discussed above, exact balance is infeasible and approximate balance must be pursued.</p>

</body>

</html>
